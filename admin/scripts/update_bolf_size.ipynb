{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import AzureCliCredential\n",
    "from azure.core.credentials import TokenCredential, AccessToken\n",
    "from requests import get\n",
    "import time\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def calc_time(string):\n",
    "    global start_time\n",
    "\n",
    "    if string == \"start\":\n",
    "        start_time = time.time()\n",
    "    else:\n",
    "        end_time = time.time()\n",
    "        return  end_time - start_time\n",
    "\n",
    "\n",
    "class CachedCredential(TokenCredential):\n",
    "  def __init__(self, delegate: TokenCredential, logger) -> None:\n",
    "    self.delegate = delegate\n",
    "    self.logger = logger\n",
    "    self._token : dict[str, AccessToken] = {}\n",
    "\n",
    "  def get_token(self, scope: str, **kwargs) -> AccessToken:\n",
    "    token = self._token.get(scope)\n",
    "    if not token or token.expiry < time.time():\n",
    "      calc_time(\"start\")\n",
    "      self._token[scope] = token = self.delegate.get_token(scope, **kwargs)\n",
    "      elapsed_time = calc_time(\"end\")\n",
    "      self.logger.info(\n",
    "            f\"Time taken to generate token(CachedCredential) is {elapsed_time:.2f} seconds.\"\n",
    "        )\n",
    "    else:\n",
    "        self.logger.info(\n",
    "            f\"Valid token exists\"\n",
    "        )\n",
    "    return token\n",
    "\n",
    "\n",
    "cachedCredential = CachedCredential(AzureCliCredential(), logger)\n",
    "\n",
    "def request_fmc_token(organization_name, stage='prod'):\n",
    "    \"\"\"\n",
    "    Get fmc token via AzureCliCredential. (Requires az login beforehand).\n",
    "\n",
    "    organization_name e.g. nrcs-2-pf, ford-dat-3, uss-gen-6-pf\n",
    "    \"\"\"\n",
    "    return cachedCredential.get_token(f'api://api-data-loop-platform-{organization_name}-{stage}/.default').token\n",
    "\n",
    "\n",
    "def get_sequences(fmc_query, organization_name, fmc_token):\n",
    "    \"\"\"\n",
    "    Does get sequences Rest call for fmc query. Returns list of sequences.\n",
    "    \"\"\"\n",
    "    fmc_headers = {\n",
    "        'Cache-Control': 'no-cache',\n",
    "        'Authorization': f'Bearer {fmc_token}',\n",
    "        'Origin': 'https://developer.bosch-data-loop.com'\n",
    "    }\n",
    "\n",
    "    sequences = []\n",
    "\n",
    "    items_per_page = 1000\n",
    "\n",
    "    is_there_more_sequences = True\n",
    "    page_index = 0\n",
    "    while is_there_more_sequences:\n",
    "        url = f'https://api.azr.bosch-data-loop.com/measurement-data-processing/v3/organizations/{organization_name}/sequence?itemsPerPage={items_per_page}&pageIndex={page_index}&filterQuery={fmc_query}'  # noqa: E501\n",
    "        response = get(url, headers=fmc_headers)\n",
    "        if response.status_code == 200:\n",
    "            response_sequences = response.json()\n",
    "            sequences.extend(response_sequences)\n",
    "            if len(response_sequences) < items_per_page:\n",
    "                is_there_more_sequences = False\n",
    "        else:\n",
    "            logger.error(f'Get sequences call to FMC failed. status_code: {response.status_code}, reason: {response.reason}, url: {url}')\n",
    "            is_there_more_sequences = False\n",
    "        page_index += 1\n",
    "        print(f'FMC query at {page_index=}')\n",
    "\n",
    "    return sequences\n",
    "\n",
    "\n",
    "organization_name = 'nrcs-2-pf'\n",
    "fmc_token = request_fmc_token(organization_name)\n",
    "fmc_query = 'SequenceCollection.id = \"811\"'\n",
    "fmc_sequences = get_sequences(fmc_query, organization_name, fmc_token)\n",
    "\n",
    "print(f'Found {len(fmc_sequences)} sequences.')\n",
    "\n",
    "def get_fmc_bolf_path(sequence) -> str | None:\n",
    "    \"\"\"Extract the BOLF path from a sequence.\"\"\"\n",
    "    for label_file in sequence['labelFiles']:\n",
    "        if label_file['domain'] == 'KPI_GENERATED_BOLF':\n",
    "            return label_file['path']\n",
    "    print(f'Warn: {sequence[\"id\"]} has no bolf linked')\n",
    "    return None\n",
    "\n",
    "def bolf_url_to_path(url: str):\n",
    "    qua_url = 'https://dypersiaqua.blob.core.windows.net/'\n",
    "    dev_url = 'https://dypersiadev.blob.core.windows.net/'\n",
    "\n",
    "    # TODO: update to use WriteOnly\n",
    "    qua_path = '/home/jovyan/data/ReadWrite/dypersiaqua/'\n",
    "    dev_path = '/home/jovyan/data/ReadWrite/dypersiadev/'\n",
    "\n",
    "    for blob_url, blob_path in [(qua_url, qua_path), (dev_url, dev_path)]:\n",
    "        if url.startswith(blob_url):\n",
    "            return blob_path + url[len(blob_url):]\n",
    "    \n",
    "    raise Exception('Unknown url path', url)\n",
    "\n",
    "bolf_links = [get_fmc_bolf_path(s) for s in fmc_sequences]\n",
    "bolf_links = [i for i in bolf_links if i]\n",
    "\n",
    "bolf_paths = [bolf_url_to_path(s) for s in bolf_links]\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from shapely import Polygon\n",
    "\n",
    "BUFFER_M = 0.15\n",
    "DRY_RUN = True\n",
    "\n",
    "bolf_backup_dir = 'bolf_backup'\n",
    "os.makedirs(bolf_backup_dir, exist_ok=True)\n",
    "\n",
    "new_bolfs_dir = 'new_bolfs'\n",
    "os.makedirs(new_bolfs_dir, exist_ok=True)\n",
    "\n",
    "def update_bolf(bolf, bolf_filename):\n",
    "    for frame in bolf['openlabel']['frames'].values():\n",
    "        for object in frame['objects'].values():\n",
    "            original_position = object['object_data']['poly3d'][0]['val']\n",
    "            original_xy = [(original_position[i], original_position[i+1]) for i in range(0, len(original_position), 3)]\n",
    "\n",
    "            if len(original_xy) <= 2:\n",
    "                print(f'Warn: In {bolf_filename} found label with 1 point. Skipping - but should be fixed by fix script')\n",
    "                continue\n",
    "\n",
    "            obstacle_poly = Polygon(original_xy)\n",
    "            obstacle_poly = obstacle_poly.buffer(BUFFER_M, cap_style='round', join_style='mitre', mitre_limit=2.0, quad_segs=3)\n",
    "            buffered_position = [coord for x, y in obstacle_poly.exterior.coords for coord in (x, y, None)][:-3] \n",
    "            object['object_data']['poly3d'][0]['val'] = buffered_position\n",
    "    \n",
    "    return bolf\n",
    "\n",
    "\n",
    "for bolf_path in bolf_paths:\n",
    "    bolf_filename = os.path.basename(bolf_path)\n",
    "    shutil.copy(bolf_path, bolf_backup_dir)\n",
    "    with open('bolf_backup.txt', 'a+') as f:\n",
    "        f.write(f'{bolf_path} {bolf_backup_dir}/{bolf_filename}\\n')\n",
    "    \n",
    "    with open(bolf_path) as f:\n",
    "        bolf = json.loads(f.read())\n",
    "    \n",
    "    bolf = update_bolf(bolf, bolf_filename)\n",
    "    \n",
    "    with open(os.path.join(new_bolfs_dir, bolf_filename), 'w') as f:\n",
    "        f.write(json.dumps(bolf))\n",
    "\n",
    "    if not DRY_RUN:\n",
    "        with open(bolf_path, 'w') as f:\n",
    "            f.write(json.dumps(bolf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
